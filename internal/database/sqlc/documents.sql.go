// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: documents.sql

package sqlc

import (
	"context"
	"time"

	"github.com/google/uuid"
	"github.com/jackc/pgx/v5/pgtype"
)

const countSearchDocuments = `-- name: CountSearchDocuments :one
SELECT COUNT(*)::int as total
FROM documents d
LEFT JOIN document_correspondents dc ON dc.document_id = d.id
LEFT JOIN correspondents c ON c.id = dc.correspondent_id
WHERE
    ($1::text IS NULL OR $1::text = ''
        OR d.search_vector @@ websearch_to_tsquery('english', $1::text))
    AND (NOT $2::boolean OR c.id = $3::uuid)
    AND (NOT $4::boolean OR d.document_date >= $5::timestamptz)
    AND (NOT $6::boolean OR d.document_date <= $7::timestamptz)
    AND (NOT $8::boolean
        OR d.id IN (
            SELECT dt.document_id
            FROM document_tags dt
            WHERE dt.tag_id = ANY($9::uuid[])
            GROUP BY dt.document_id
            HAVING COUNT(DISTINCT dt.tag_id) = $10::int
        ))
`

type CountSearchDocumentsParams struct {
	Query            *string     `json:"query"`
	HasCorrespondent bool        `json:"has_correspondent"`
	CorrespondentID  uuid.UUID   `json:"correspondent_id"`
	HasDateFrom      bool        `json:"has_date_from"`
	DateFrom         time.Time   `json:"date_from"`
	HasDateTo        bool        `json:"has_date_to"`
	DateTo           time.Time   `json:"date_to"`
	HasTags          bool        `json:"has_tags"`
	TagIds           []uuid.UUID `json:"tag_ids"`
	TagCount         int32       `json:"tag_count"`
}

func (q *Queries) CountSearchDocuments(ctx context.Context, arg CountSearchDocumentsParams) (int32, error) {
	row := q.db.QueryRow(ctx, countSearchDocuments,
		arg.Query,
		arg.HasCorrespondent,
		arg.CorrespondentID,
		arg.HasDateFrom,
		arg.DateFrom,
		arg.HasDateTo,
		arg.DateTo,
		arg.HasTags,
		arg.TagIds,
		arg.TagCount,
	)
	var total int32
	err := row.Scan(&total)
	return total, err
}

const createDocument = `-- name: CreateDocument :one
INSERT INTO documents (id, original_filename, content_hash, file_size, page_count, pdf_title, pdf_author, pdf_created_at, document_date)
VALUES ($1, $2, $3, $4, $5, $6, $7, $8, COALESCE($9, NOW()))
RETURNING id, original_filename, content_hash, file_size, page_count, pdf_title, pdf_author, pdf_created_at, document_date, created_at, updated_at, processing_status, text_content, thumbnail_generated, processing_error, processed_at, search_vector
`

type CreateDocumentParams struct {
	ID               uuid.UUID          `json:"id"`
	OriginalFilename string             `json:"original_filename"`
	ContentHash      string             `json:"content_hash"`
	FileSize         int64              `json:"file_size"`
	PageCount        *int32             `json:"page_count"`
	PdfTitle         *string            `json:"pdf_title"`
	PdfAuthor        *string            `json:"pdf_author"`
	PdfCreatedAt     pgtype.Timestamptz `json:"pdf_created_at"`
	Column9          pgtype.Timestamptz `json:"column_9"`
}

func (q *Queries) CreateDocument(ctx context.Context, arg CreateDocumentParams) (Document, error) {
	row := q.db.QueryRow(ctx, createDocument,
		arg.ID,
		arg.OriginalFilename,
		arg.ContentHash,
		arg.FileSize,
		arg.PageCount,
		arg.PdfTitle,
		arg.PdfAuthor,
		arg.PdfCreatedAt,
		arg.Column9,
	)
	var i Document
	err := row.Scan(
		&i.ID,
		&i.OriginalFilename,
		&i.ContentHash,
		&i.FileSize,
		&i.PageCount,
		&i.PdfTitle,
		&i.PdfAuthor,
		&i.PdfCreatedAt,
		&i.DocumentDate,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.ProcessingStatus,
		&i.TextContent,
		&i.ThumbnailGenerated,
		&i.ProcessingError,
		&i.ProcessedAt,
		&i.SearchVector,
	)
	return i, err
}

const createDocumentEvent = `-- name: CreateDocumentEvent :one
INSERT INTO document_events (document_id, event_type, payload, error_message, duration_ms)
VALUES ($1, $2, $3, $4, $5)
RETURNING id, document_id, event_type, payload, error_message, duration_ms, created_at
`

type CreateDocumentEventParams struct {
	DocumentID   uuid.UUID `json:"document_id"`
	EventType    string    `json:"event_type"`
	Payload      []byte    `json:"payload"`
	ErrorMessage *string   `json:"error_message"`
	DurationMs   *int32    `json:"duration_ms"`
}

func (q *Queries) CreateDocumentEvent(ctx context.Context, arg CreateDocumentEventParams) (DocumentEvent, error) {
	row := q.db.QueryRow(ctx, createDocumentEvent,
		arg.DocumentID,
		arg.EventType,
		arg.Payload,
		arg.ErrorMessage,
		arg.DurationMs,
	)
	var i DocumentEvent
	err := row.Scan(
		&i.ID,
		&i.DocumentID,
		&i.EventType,
		&i.Payload,
		&i.ErrorMessage,
		&i.DurationMs,
		&i.CreatedAt,
	)
	return i, err
}

const deleteDocument = `-- name: DeleteDocument :exec
DELETE FROM documents WHERE id = $1
`

func (q *Queries) DeleteDocument(ctx context.Context, id uuid.UUID) error {
	_, err := q.db.Exec(ctx, deleteDocument, id)
	return err
}

const getDocument = `-- name: GetDocument :one
SELECT id, original_filename, content_hash, file_size, page_count, pdf_title, pdf_author, pdf_created_at, document_date, created_at, updated_at, processing_status, text_content, thumbnail_generated, processing_error, processed_at, search_vector FROM documents WHERE id = $1
`

func (q *Queries) GetDocument(ctx context.Context, id uuid.UUID) (Document, error) {
	row := q.db.QueryRow(ctx, getDocument, id)
	var i Document
	err := row.Scan(
		&i.ID,
		&i.OriginalFilename,
		&i.ContentHash,
		&i.FileSize,
		&i.PageCount,
		&i.PdfTitle,
		&i.PdfAuthor,
		&i.PdfCreatedAt,
		&i.DocumentDate,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.ProcessingStatus,
		&i.TextContent,
		&i.ThumbnailGenerated,
		&i.ProcessingError,
		&i.ProcessedAt,
		&i.SearchVector,
	)
	return i, err
}

const getDocumentByHash = `-- name: GetDocumentByHash :one
SELECT id, original_filename, content_hash, file_size, page_count, pdf_title, pdf_author, pdf_created_at, document_date, created_at, updated_at, processing_status, text_content, thumbnail_generated, processing_error, processed_at, search_vector FROM documents WHERE content_hash = $1
`

func (q *Queries) GetDocumentByHash(ctx context.Context, contentHash string) (Document, error) {
	row := q.db.QueryRow(ctx, getDocumentByHash, contentHash)
	var i Document
	err := row.Scan(
		&i.ID,
		&i.OriginalFilename,
		&i.ContentHash,
		&i.FileSize,
		&i.PageCount,
		&i.PdfTitle,
		&i.PdfAuthor,
		&i.PdfCreatedAt,
		&i.DocumentDate,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.ProcessingStatus,
		&i.TextContent,
		&i.ThumbnailGenerated,
		&i.ProcessingError,
		&i.ProcessedAt,
		&i.SearchVector,
	)
	return i, err
}

const getDocumentEvents = `-- name: GetDocumentEvents :many
SELECT id, document_id, event_type, payload, error_message, duration_ms, created_at FROM document_events WHERE document_id = $1 ORDER BY created_at DESC
`

func (q *Queries) GetDocumentEvents(ctx context.Context, documentID uuid.UUID) ([]DocumentEvent, error) {
	rows, err := q.db.Query(ctx, getDocumentEvents, documentID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []DocumentEvent{}
	for rows.Next() {
		var i DocumentEvent
		if err := rows.Scan(
			&i.ID,
			&i.DocumentID,
			&i.EventType,
			&i.Payload,
			&i.ErrorMessage,
			&i.DurationMs,
			&i.CreatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getLatestDocumentEvent = `-- name: GetLatestDocumentEvent :one
SELECT id, document_id, event_type, payload, error_message, duration_ms, created_at FROM document_events WHERE document_id = $1 ORDER BY created_at DESC LIMIT 1
`

func (q *Queries) GetLatestDocumentEvent(ctx context.Context, documentID uuid.UUID) (DocumentEvent, error) {
	row := q.db.QueryRow(ctx, getLatestDocumentEvent, documentID)
	var i DocumentEvent
	err := row.Scan(
		&i.ID,
		&i.DocumentID,
		&i.EventType,
		&i.Payload,
		&i.ErrorMessage,
		&i.DurationMs,
		&i.CreatedAt,
	)
	return i, err
}

const getPendingProcessingDocuments = `-- name: GetPendingProcessingDocuments :many
SELECT id, original_filename, content_hash, file_size, page_count, pdf_title, pdf_author, pdf_created_at, document_date, created_at, updated_at, processing_status, text_content, thumbnail_generated, processing_error, processed_at, search_vector FROM documents
WHERE processing_status = 'pending'
ORDER BY created_at ASC
LIMIT $1
`

func (q *Queries) GetPendingProcessingDocuments(ctx context.Context, limit int64) ([]Document, error) {
	rows, err := q.db.Query(ctx, getPendingProcessingDocuments, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Document{}
	for rows.Next() {
		var i Document
		if err := rows.Scan(
			&i.ID,
			&i.OriginalFilename,
			&i.ContentHash,
			&i.FileSize,
			&i.PageCount,
			&i.PdfTitle,
			&i.PdfAuthor,
			&i.PdfCreatedAt,
			&i.DocumentDate,
			&i.CreatedAt,
			&i.UpdatedAt,
			&i.ProcessingStatus,
			&i.TextContent,
			&i.ThumbnailGenerated,
			&i.ProcessingError,
			&i.ProcessedAt,
			&i.SearchVector,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listDocuments = `-- name: ListDocuments :many
SELECT id, original_filename, content_hash, file_size, page_count, pdf_title, pdf_author, pdf_created_at, document_date, created_at, updated_at, processing_status, text_content, thumbnail_generated, processing_error, processed_at, search_vector FROM documents ORDER BY created_at DESC LIMIT $1 OFFSET $2
`

type ListDocumentsParams struct {
	Limit  int64 `json:"limit"`
	Offset int64 `json:"offset"`
}

func (q *Queries) ListDocuments(ctx context.Context, arg ListDocumentsParams) ([]Document, error) {
	rows, err := q.db.Query(ctx, listDocuments, arg.Limit, arg.Offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []Document{}
	for rows.Next() {
		var i Document
		if err := rows.Scan(
			&i.ID,
			&i.OriginalFilename,
			&i.ContentHash,
			&i.FileSize,
			&i.PageCount,
			&i.PdfTitle,
			&i.PdfAuthor,
			&i.PdfCreatedAt,
			&i.DocumentDate,
			&i.CreatedAt,
			&i.UpdatedAt,
			&i.ProcessingStatus,
			&i.TextContent,
			&i.ThumbnailGenerated,
			&i.ProcessingError,
			&i.ProcessedAt,
			&i.SearchVector,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listDocumentsWithCorrespondent = `-- name: ListDocumentsWithCorrespondent :many
SELECT d.id, d.original_filename, d.content_hash, d.file_size, d.page_count, d.pdf_title, d.pdf_author, d.pdf_created_at, d.document_date, d.created_at, d.updated_at, d.processing_status, d.text_content, d.thumbnail_generated, d.processing_error, d.processed_at, d.search_vector, c.id as correspondent_id, c.name as correspondent_name
FROM documents d
LEFT JOIN document_correspondents dc ON dc.document_id = d.id
LEFT JOIN correspondents c ON c.id = dc.correspondent_id
ORDER BY d.created_at DESC
LIMIT $1 OFFSET $2
`

type ListDocumentsWithCorrespondentParams struct {
	Limit  int64 `json:"limit"`
	Offset int64 `json:"offset"`
}

type ListDocumentsWithCorrespondentRow struct {
	ID                 uuid.UUID          `json:"id"`
	OriginalFilename   string             `json:"original_filename"`
	ContentHash        string             `json:"content_hash"`
	FileSize           int64              `json:"file_size"`
	PageCount          *int32             `json:"page_count"`
	PdfTitle           *string            `json:"pdf_title"`
	PdfAuthor          *string            `json:"pdf_author"`
	PdfCreatedAt       pgtype.Timestamptz `json:"pdf_created_at"`
	DocumentDate       time.Time          `json:"document_date"`
	CreatedAt          time.Time          `json:"created_at"`
	UpdatedAt          time.Time          `json:"updated_at"`
	ProcessingStatus   ProcessingStatus   `json:"processing_status"`
	TextContent        *string            `json:"text_content"`
	ThumbnailGenerated bool               `json:"thumbnail_generated"`
	ProcessingError    *string            `json:"processing_error"`
	ProcessedAt        pgtype.Timestamptz `json:"processed_at"`
	SearchVector       interface{}        `json:"search_vector"`
	CorrespondentID    pgtype.UUID        `json:"correspondent_id"`
	CorrespondentName  *string            `json:"correspondent_name"`
}

func (q *Queries) ListDocumentsWithCorrespondent(ctx context.Context, arg ListDocumentsWithCorrespondentParams) ([]ListDocumentsWithCorrespondentRow, error) {
	rows, err := q.db.Query(ctx, listDocumentsWithCorrespondent, arg.Limit, arg.Offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []ListDocumentsWithCorrespondentRow{}
	for rows.Next() {
		var i ListDocumentsWithCorrespondentRow
		if err := rows.Scan(
			&i.ID,
			&i.OriginalFilename,
			&i.ContentHash,
			&i.FileSize,
			&i.PageCount,
			&i.PdfTitle,
			&i.PdfAuthor,
			&i.PdfCreatedAt,
			&i.DocumentDate,
			&i.CreatedAt,
			&i.UpdatedAt,
			&i.ProcessingStatus,
			&i.TextContent,
			&i.ThumbnailGenerated,
			&i.ProcessingError,
			&i.ProcessedAt,
			&i.SearchVector,
			&i.CorrespondentID,
			&i.CorrespondentName,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchDocuments = `-- name: SearchDocuments :many
SELECT
    d.id, d.original_filename, d.content_hash, d.file_size, d.page_count, d.pdf_title, d.pdf_author, d.pdf_created_at, d.document_date, d.created_at, d.updated_at, d.processing_status, d.text_content, d.thumbnail_generated, d.processing_error, d.processed_at, d.search_vector,
    c.id as correspondent_id,
    c.name as correspondent_name,
    CASE WHEN $1::text IS NOT NULL AND $1::text != ''
         THEN ts_rank(d.search_vector, websearch_to_tsquery('english', $1::text))
         ELSE 0 END as rank,
    CASE WHEN $1::text IS NOT NULL AND $1::text != ''
         THEN ts_headline('english', COALESCE(d.text_content, ''), websearch_to_tsquery('english', $1::text),
              'MaxFragments=1, MaxWords=30, MinWords=15, StartSel=<mark>, StopSel=</mark>')
         ELSE '' END as headline
FROM documents d
LEFT JOIN document_correspondents dc ON dc.document_id = d.id
LEFT JOIN correspondents c ON c.id = dc.correspondent_id
WHERE
    -- Full-text search (optional - empty/null matches all)
    ($1::text IS NULL OR $1::text = ''
        OR d.search_vector @@ websearch_to_tsquery('english', $1::text))
    -- Correspondent filter (optional)
    AND (NOT $2::boolean OR c.id = $3::uuid)
    -- Date range filter (optional)
    AND (NOT $4::boolean OR d.document_date >= $5::timestamptz)
    AND (NOT $6::boolean OR d.document_date <= $7::timestamptz)
    -- Tag filter (optional - AND logic: must have ALL selected tags)
    AND (NOT $8::boolean
        OR d.id IN (
            SELECT dt.document_id
            FROM document_tags dt
            WHERE dt.tag_id = ANY($9::uuid[])
            GROUP BY dt.document_id
            HAVING COUNT(DISTINCT dt.tag_id) = $10::int
        ))
ORDER BY
    CASE WHEN $1::text IS NOT NULL AND $1::text != ''
         THEN ts_rank(d.search_vector, websearch_to_tsquery('english', $1::text))
         ELSE 0 END DESC,
    d.document_date DESC NULLS LAST
LIMIT $12 OFFSET $11
`

type SearchDocumentsParams struct {
	Query            *string     `json:"query"`
	HasCorrespondent bool        `json:"has_correspondent"`
	CorrespondentID  uuid.UUID   `json:"correspondent_id"`
	HasDateFrom      bool        `json:"has_date_from"`
	DateFrom         time.Time   `json:"date_from"`
	HasDateTo        bool        `json:"has_date_to"`
	DateTo           time.Time   `json:"date_to"`
	HasTags          bool        `json:"has_tags"`
	TagIds           []uuid.UUID `json:"tag_ids"`
	TagCount         int32       `json:"tag_count"`
	OffsetCount      int64       `json:"offset_count"`
	LimitCount       int64       `json:"limit_count"`
}

type SearchDocumentsRow struct {
	ID                 uuid.UUID          `json:"id"`
	OriginalFilename   string             `json:"original_filename"`
	ContentHash        string             `json:"content_hash"`
	FileSize           int64              `json:"file_size"`
	PageCount          *int32             `json:"page_count"`
	PdfTitle           *string            `json:"pdf_title"`
	PdfAuthor          *string            `json:"pdf_author"`
	PdfCreatedAt       pgtype.Timestamptz `json:"pdf_created_at"`
	DocumentDate       time.Time          `json:"document_date"`
	CreatedAt          time.Time          `json:"created_at"`
	UpdatedAt          time.Time          `json:"updated_at"`
	ProcessingStatus   ProcessingStatus   `json:"processing_status"`
	TextContent        *string            `json:"text_content"`
	ThumbnailGenerated bool               `json:"thumbnail_generated"`
	ProcessingError    *string            `json:"processing_error"`
	ProcessedAt        pgtype.Timestamptz `json:"processed_at"`
	SearchVector       interface{}        `json:"search_vector"`
	CorrespondentID    pgtype.UUID        `json:"correspondent_id"`
	CorrespondentName  *string            `json:"correspondent_name"`
	Rank               float32            `json:"rank"`
	Headline           string             `json:"headline"`
}

func (q *Queries) SearchDocuments(ctx context.Context, arg SearchDocumentsParams) ([]SearchDocumentsRow, error) {
	rows, err := q.db.Query(ctx, searchDocuments,
		arg.Query,
		arg.HasCorrespondent,
		arg.CorrespondentID,
		arg.HasDateFrom,
		arg.DateFrom,
		arg.HasDateTo,
		arg.DateTo,
		arg.HasTags,
		arg.TagIds,
		arg.TagCount,
		arg.OffsetCount,
		arg.LimitCount,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	items := []SearchDocumentsRow{}
	for rows.Next() {
		var i SearchDocumentsRow
		if err := rows.Scan(
			&i.ID,
			&i.OriginalFilename,
			&i.ContentHash,
			&i.FileSize,
			&i.PageCount,
			&i.PdfTitle,
			&i.PdfAuthor,
			&i.PdfCreatedAt,
			&i.DocumentDate,
			&i.CreatedAt,
			&i.UpdatedAt,
			&i.ProcessingStatus,
			&i.TextContent,
			&i.ThumbnailGenerated,
			&i.ProcessingError,
			&i.ProcessedAt,
			&i.SearchVector,
			&i.CorrespondentID,
			&i.CorrespondentName,
			&i.Rank,
			&i.Headline,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const setDocumentProcessingStatus = `-- name: SetDocumentProcessingStatus :one
UPDATE documents SET
    processing_status = $2,
    updated_at = NOW()
WHERE id = $1
RETURNING id, original_filename, content_hash, file_size, page_count, pdf_title, pdf_author, pdf_created_at, document_date, created_at, updated_at, processing_status, text_content, thumbnail_generated, processing_error, processed_at, search_vector
`

type SetDocumentProcessingStatusParams struct {
	ID               uuid.UUID        `json:"id"`
	ProcessingStatus ProcessingStatus `json:"processing_status"`
}

func (q *Queries) SetDocumentProcessingStatus(ctx context.Context, arg SetDocumentProcessingStatusParams) (Document, error) {
	row := q.db.QueryRow(ctx, setDocumentProcessingStatus, arg.ID, arg.ProcessingStatus)
	var i Document
	err := row.Scan(
		&i.ID,
		&i.OriginalFilename,
		&i.ContentHash,
		&i.FileSize,
		&i.PageCount,
		&i.PdfTitle,
		&i.PdfAuthor,
		&i.PdfCreatedAt,
		&i.DocumentDate,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.ProcessingStatus,
		&i.TextContent,
		&i.ThumbnailGenerated,
		&i.ProcessingError,
		&i.ProcessedAt,
		&i.SearchVector,
	)
	return i, err
}

const updateDocument = `-- name: UpdateDocument :one
UPDATE documents SET
  document_date = COALESCE($2, document_date),
  updated_at = NOW()
WHERE id = $1
RETURNING id, original_filename, content_hash, file_size, page_count, pdf_title, pdf_author, pdf_created_at, document_date, created_at, updated_at, processing_status, text_content, thumbnail_generated, processing_error, processed_at, search_vector
`

type UpdateDocumentParams struct {
	ID           uuid.UUID          `json:"id"`
	DocumentDate pgtype.Timestamptz `json:"document_date"`
}

func (q *Queries) UpdateDocument(ctx context.Context, arg UpdateDocumentParams) (Document, error) {
	row := q.db.QueryRow(ctx, updateDocument, arg.ID, arg.DocumentDate)
	var i Document
	err := row.Scan(
		&i.ID,
		&i.OriginalFilename,
		&i.ContentHash,
		&i.FileSize,
		&i.PageCount,
		&i.PdfTitle,
		&i.PdfAuthor,
		&i.PdfCreatedAt,
		&i.DocumentDate,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.ProcessingStatus,
		&i.TextContent,
		&i.ThumbnailGenerated,
		&i.ProcessingError,
		&i.ProcessedAt,
		&i.SearchVector,
	)
	return i, err
}

const updateDocumentProcessing = `-- name: UpdateDocumentProcessing :one
UPDATE documents SET
    text_content = $2,
    thumbnail_generated = $3,
    processing_status = $4,
    processing_error = $5,
    processed_at = $6,
    updated_at = NOW()
WHERE id = $1
RETURNING id, original_filename, content_hash, file_size, page_count, pdf_title, pdf_author, pdf_created_at, document_date, created_at, updated_at, processing_status, text_content, thumbnail_generated, processing_error, processed_at, search_vector
`

type UpdateDocumentProcessingParams struct {
	ID                 uuid.UUID          `json:"id"`
	TextContent        *string            `json:"text_content"`
	ThumbnailGenerated bool               `json:"thumbnail_generated"`
	ProcessingStatus   ProcessingStatus   `json:"processing_status"`
	ProcessingError    *string            `json:"processing_error"`
	ProcessedAt        pgtype.Timestamptz `json:"processed_at"`
}

func (q *Queries) UpdateDocumentProcessing(ctx context.Context, arg UpdateDocumentProcessingParams) (Document, error) {
	row := q.db.QueryRow(ctx, updateDocumentProcessing,
		arg.ID,
		arg.TextContent,
		arg.ThumbnailGenerated,
		arg.ProcessingStatus,
		arg.ProcessingError,
		arg.ProcessedAt,
	)
	var i Document
	err := row.Scan(
		&i.ID,
		&i.OriginalFilename,
		&i.ContentHash,
		&i.FileSize,
		&i.PageCount,
		&i.PdfTitle,
		&i.PdfAuthor,
		&i.PdfCreatedAt,
		&i.DocumentDate,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.ProcessingStatus,
		&i.TextContent,
		&i.ThumbnailGenerated,
		&i.ProcessingError,
		&i.ProcessedAt,
		&i.SearchVector,
	)
	return i, err
}
