---
phase: 08-ai-integration
plan: 03
type: execute
wave: 2
depends_on: ["08-01", "08-02"]
files_modified:
  - internal/ai/service.go
  - internal/processing/ai_processor.go
  - cmd/server/main.go
autonomous: true

must_haves:
  truths:
    - "AI service can analyze documents using configured provider"
    - "High-confidence suggestions auto-apply immediately"
    - "Low-confidence suggestions are stored as pending for review"
    - "AI processing runs asynchronously via job queue"
  artifacts:
    - path: "internal/ai/service.go"
      provides: "AI service with provider fallback and suggestion workflow"
      exports: ["Service", "AnalyzeDocument"]
    - path: "internal/processing/ai_processor.go"
      provides: "Job handler for AI processing queue"
      exports: ["AIProcessor", "HandleJob"]
  key_links:
    - from: "internal/ai/service.go"
      to: "internal/ai/ai.go"
      via: "Provider interface"
      pattern: "Provider.Analyze"
    - from: "internal/processing/ai_processor.go"
      to: "internal/ai/service.go"
      via: "Service.AnalyzeDocument"
      pattern: "aiSvc.AnalyzeDocument"
---

<objective>
Create AI service with provider orchestration and job handler for async processing.

Purpose: The AI service orchestrates provider selection (with fallback), analyzes documents, stores suggestions with proper status (auto-applied vs pending), and tracks usage. The job handler integrates with the existing queue infrastructure.
Output: AI service and processor ready for handler integration.
</objective>

<execution_context>
@/home/bjk/.claude/get-shit-done/workflows/execute-plan.md
@/home/bjk/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-ai-integration/08-CONTEXT.md
@.planning/phases/08-ai-integration/08-RESEARCH.md
@.planning/phases/08-ai-integration/08-01-SUMMARY.md
@.planning/phases/08-ai-integration/08-02-SUMMARY.md
@internal/queue/queue.go
@internal/processing/processor.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create AI service with provider orchestration</name>
  <files>internal/ai/service.go</files>
  <action>
Create the AI service that orchestrates providers and manages suggestions:

```go
package ai

import (
    "context"
    "fmt"
    "log/slog"
    "strings"

    "github.com/google/uuid"
    "github.com/jackc/pgx/v5/pgtype"

    "docko/internal/database"
    "docko/internal/database/sqlc"
)

// Service orchestrates AI analysis and suggestion management
type Service struct {
    db        *database.DB
    providers []Provider
}

// NewService creates a new AI service with all available providers
func NewService(db *database.DB) *Service {
    providers := []Provider{
        NewOpenAIProvider(),
        NewAnthropicProvider(),
        NewOllamaProvider(),
    }
    return &Service{
        db:        db,
        providers: providers,
    }
}

// GetSettings returns the current AI settings
func (s *Service) GetSettings(ctx context.Context) (*sqlc.AiSetting, error) {
    settings, err := s.db.Queries.GetAISettings(ctx)
    if err != nil {
        return nil, fmt.Errorf("get ai settings: %w", err)
    }
    return &settings, nil
}

// UpdateSettings updates AI settings
func (s *Service) UpdateSettings(ctx context.Context, params sqlc.UpdateAISettingsParams) (*sqlc.AiSetting, error) {
    settings, err := s.db.Queries.UpdateAISettings(ctx, params)
    if err != nil {
        return nil, fmt.Errorf("update ai settings: %w", err)
    }
    return &settings, nil
}

// AvailableProviders returns list of configured provider names
func (s *Service) AvailableProviders() []string {
    var names []string
    for _, p := range s.providers {
        if p.Available() {
            names = append(names, p.Name())
        }
    }
    return names
}

// AnalyzeDocument analyzes a document and stores suggestions
// Returns the suggestions created (auto-applied or pending)
func (s *Service) AnalyzeDocument(ctx context.Context, docID uuid.UUID, jobID *uuid.UUID) ([]sqlc.AiSuggestion, error) {
    // Get settings
    settings, err := s.GetSettings(ctx)
    if err != nil {
        return nil, err
    }

    // Get document
    doc, err := s.db.Queries.GetDocument(ctx, docID)
    if err != nil {
        return nil, fmt.Errorf("get document: %w", err)
    }

    // Check if document has text content
    if doc.TextContent == nil || *doc.TextContent == "" {
        return nil, fmt.Errorf("document has no text content")
    }

    // Get existing tags and correspondents for context
    tags, err := s.db.Queries.ListTags(ctx)
    if err != nil {
        return nil, fmt.Errorf("list tags: %w", err)
    }
    tagNames := make([]string, len(tags))
    for i, t := range tags {
        tagNames[i] = t.Name
    }

    correspondents, err := s.db.Queries.ListCorrespondents(ctx)
    if err != nil {
        return nil, fmt.Errorf("list correspondents: %w", err)
    }
    corrNames := make([]string, len(correspondents))
    for i, c := range correspondents {
        corrNames[i] = c.Name
    }

    // Truncate text to max pages (rough estimate: 3000 chars per page)
    maxChars := int(settings.MaxPages) * 3000
    textContent := *doc.TextContent
    if len(textContent) > maxChars {
        textContent = textContent[:maxChars]
    }

    // Build request
    req := AnalyzeRequest{
        DocumentID:     docID,
        TextContent:    textContent,
        ExistingTags:   tagNames,
        Correspondents: corrNames,
        MaxTokens:      1024,
    }

    // Analyze with provider fallback
    resp, provider, err := s.analyzeWithFallback(ctx, req, settings.PreferredProvider)
    if err != nil {
        return nil, err
    }

    // Record usage
    var jobIDParam pgtype.UUID
    if jobID != nil {
        jobIDParam = pgtype.UUID{Bytes: *jobID, Valid: true}
    }
    _, err = s.db.Queries.CreateAIUsage(ctx, sqlc.CreateAIUsageParams{
        DocumentID:   docID,
        JobID:        jobIDParam,
        Provider:     provider,
        Model:        resp.Usage.Model,
        InputTokens:  int32(resp.Usage.InputTokens),
        OutputTokens: int32(resp.Usage.OutputTokens),
    })
    if err != nil {
        slog.Error("failed to record ai usage", "error", err)
        // Continue - usage tracking is not critical
    }

    // Store suggestions and apply high-confidence ones
    return s.storeSuggestions(ctx, docID, jobID, resp.Suggestions, settings)
}

// analyzeWithFallback tries providers in order
func (s *Service) analyzeWithFallback(ctx context.Context, req AnalyzeRequest, preferredProvider *string) (*AnalyzeResponse, string, error) {
    providers := s.getOrderedProviders(preferredProvider)

    var lastErr error
    for _, p := range providers {
        if !p.Available() {
            continue
        }

        slog.Info("analyzing document with provider",
            "provider", p.Name(),
            "doc_id", req.DocumentID)

        resp, err := p.Analyze(ctx, req)
        if err != nil {
            lastErr = err
            slog.Warn("provider failed, trying next",
                "provider", p.Name(),
                "error", err)
            continue
        }
        return resp, p.Name(), nil
    }

    if lastErr != nil {
        return nil, "", fmt.Errorf("all providers failed: %w", lastErr)
    }
    return nil, "", fmt.Errorf("no ai providers available")
}

// getOrderedProviders returns providers with preferred first
func (s *Service) getOrderedProviders(preferred *string) []Provider {
    if preferred == nil || *preferred == "" {
        return s.providers
    }

    ordered := make([]Provider, 0, len(s.providers))
    // Add preferred first
    for _, p := range s.providers {
        if p.Name() == *preferred {
            ordered = append(ordered, p)
            break
        }
    }
    // Add rest
    for _, p := range s.providers {
        if p.Name() != *preferred {
            ordered = append(ordered, p)
        }
    }
    return ordered
}

// storeSuggestions saves suggestions and auto-applies high-confidence ones
func (s *Service) storeSuggestions(ctx context.Context, docID uuid.UUID, jobID *uuid.UUID, suggestions []Suggestion, settings *sqlc.AiSetting) ([]sqlc.AiSuggestion, error) {
    var stored []sqlc.AiSuggestion

    autoThreshold, _ := settings.AutoApplyThreshold.Float64Value()
    reviewThreshold, _ := settings.ReviewThreshold.Float64Value()

    for _, sug := range suggestions {
        // Skip low-confidence suggestions
        if sug.Confidence < reviewThreshold.Float64 {
            slog.Debug("skipping low-confidence suggestion",
                "type", sug.Type,
                "value", sug.Value,
                "confidence", sug.Confidence)
            continue
        }

        // Determine status
        status := sqlc.SuggestionStatusPending
        var resolvedAt pgtype.Timestamptz
        var resolvedBy *string

        if sug.Confidence >= autoThreshold.Float64 {
            status = sqlc.SuggestionStatusAutoApplied
            resolvedAt = pgtype.Timestamptz{Time: ctx.Value("now").(interface{ Now() interface{} }).(interface{}).(interface{}), Valid: true}
            // Actually use time.Now()
            resolvedBy = strPtr("auto")
        }

        // Create suggestion record
        var jobIDParam pgtype.UUID
        if jobID != nil {
            jobIDParam = pgtype.UUID{Bytes: *jobID, Valid: true}
        }

        sugType := sqlc.SuggestionTypeTag
        if sug.Type == "correspondent" {
            sugType = sqlc.SuggestionTypeCorrespondent
        }

        suggestion, err := s.db.Queries.CreateAISuggestion(ctx, sqlc.CreateAISuggestionParams{
            DocumentID:     docID,
            JobID:          jobIDParam,
            SuggestionType: sugType,
            Value:          sug.Value,
            Confidence:     pgtype.Numeric{}, // Will set via string conversion
            Reasoning:      &sug.Reasoning,
            IsNew:          sug.IsNew,
            Status:         status,
            ResolvedAt:     resolvedAt,
            ResolvedBy:     resolvedBy,
        })
        if err != nil {
            slog.Error("failed to create suggestion", "error", err)
            continue
        }

        stored = append(stored, suggestion)

        // Auto-apply if high confidence
        if status == sqlc.SuggestionStatusAutoApplied {
            if err := s.applySuggestion(ctx, docID, sug); err != nil {
                slog.Error("failed to auto-apply suggestion",
                    "error", err,
                    "type", sug.Type,
                    "value", sug.Value)
            }
        }
    }

    return stored, nil
}

// applySuggestion applies a tag or correspondent to a document
func (s *Service) applySuggestion(ctx context.Context, docID uuid.UUID, sug Suggestion) error {
    if sug.Type == "tag" {
        return s.applyTagSuggestion(ctx, docID, sug)
    }
    return s.applyCorrespondentSuggestion(ctx, docID, sug)
}

// applyTagSuggestion creates tag if new and assigns to document
func (s *Service) applyTagSuggestion(ctx context.Context, docID uuid.UUID, sug Suggestion) error {
    // Find or create tag
    var tagID uuid.UUID
    if sug.IsNew {
        // Create new tag
        tag, err := s.db.Queries.CreateTag(ctx, sqlc.CreateTagParams{
            Name:  sug.Value,
            Color: nil,
        })
        if err != nil {
            // Tag might already exist (race condition)
            if !strings.Contains(err.Error(), "duplicate") {
                return fmt.Errorf("create tag: %w", err)
            }
            // Find existing
            tags, _ := s.db.Queries.ListTags(ctx)
            for _, t := range tags {
                if t.Name == sug.Value {
                    tagID = t.ID
                    break
                }
            }
        } else {
            tagID = tag.ID
        }
    } else {
        // Find existing tag
        tags, err := s.db.Queries.ListTags(ctx)
        if err != nil {
            return fmt.Errorf("list tags: %w", err)
        }
        for _, t := range tags {
            if t.Name == sug.Value {
                tagID = t.ID
                break
            }
        }
    }

    if tagID == uuid.Nil {
        return fmt.Errorf("tag not found: %s", sug.Value)
    }

    // Add tag to document
    err := s.db.Queries.AddDocumentTag(ctx, sqlc.AddDocumentTagParams{
        DocumentID: docID,
        TagID:      tagID,
    })
    if err != nil && !strings.Contains(err.Error(), "duplicate") {
        return fmt.Errorf("add document tag: %w", err)
    }

    slog.Info("auto-applied tag",
        "doc_id", docID,
        "tag", sug.Value,
        "new", sug.IsNew)
    return nil
}

// applyCorrespondentSuggestion creates correspondent if new and assigns to document
func (s *Service) applyCorrespondentSuggestion(ctx context.Context, docID uuid.UUID, sug Suggestion) error {
    // Find or create correspondent
    var corrID uuid.UUID
    if sug.IsNew {
        // Create new correspondent
        corr, err := s.db.Queries.CreateCorrespondent(ctx, sqlc.CreateCorrespondentParams{
            Name:  sug.Value,
            Notes: nil,
        })
        if err != nil {
            if !strings.Contains(err.Error(), "duplicate") {
                return fmt.Errorf("create correspondent: %w", err)
            }
            // Find existing
            correspondents, _ := s.db.Queries.ListCorrespondents(ctx)
            for _, c := range correspondents {
                if c.Name == sug.Value {
                    corrID = c.ID
                    break
                }
            }
        } else {
            corrID = corr.ID
        }
    } else {
        // Find existing correspondent
        correspondents, err := s.db.Queries.ListCorrespondents(ctx)
        if err != nil {
            return fmt.Errorf("list correspondents: %w", err)
        }
        for _, c := range correspondents {
            if c.Name == sug.Value {
                corrID = c.ID
                break
            }
        }
    }

    if corrID == uuid.Nil {
        return fmt.Errorf("correspondent not found: %s", sug.Value)
    }

    // Set document correspondent
    err := s.db.Queries.SetDocumentCorrespondent(ctx, sqlc.SetDocumentCorrespondentParams{
        DocumentID:      docID,
        CorrespondentID: corrID,
    })
    if err != nil {
        return fmt.Errorf("set document correspondent: %w", err)
    }

    slog.Info("auto-applied correspondent",
        "doc_id", docID,
        "correspondent", sug.Value,
        "new", sug.IsNew)
    return nil
}

// GetUsageStats returns AI usage statistics
func (s *Service) GetUsageStats(ctx context.Context) (*UsageStats, error) {
    stats, err := s.db.Queries.GetAIUsageStats(ctx)
    if err != nil {
        return nil, fmt.Errorf("get usage stats: %w", err)
    }
    return &UsageStats{
        DocumentsProcessed: stats.DocumentsProcessed,
        TotalInputTokens:   stats.TotalInputTokens,
        TotalOutputTokens:  stats.TotalOutputTokens,
    }, nil
}

// UsageStats holds aggregate usage data
type UsageStats struct {
    DocumentsProcessed int64
    TotalInputTokens   int64
    TotalOutputTokens  int64
}

func strPtr(s string) *string {
    return &s
}
```

Note: The confidence field handling with pgtype.Numeric needs adjustment - use string parsing or direct float. Fix during implementation based on sqlc generated types.
  </action>
  <verify>Check ./tmp/air-combined.log for compilation errors</verify>
  <done>AI service compiles with provider fallback and suggestion storage</done>
</task>

<task type="auto">
  <name>Task 2: Create AI processor job handler</name>
  <files>internal/processing/ai_processor.go</files>
  <action>
Create the AI job handler that integrates with the queue:

```go
package processing

import (
    "context"
    "encoding/json"
    "fmt"
    "log/slog"
    "time"

    "github.com/google/uuid"

    "docko/internal/ai"
    "docko/internal/database/sqlc"
)

// AIProcessor handles AI analysis jobs
type AIProcessor struct {
    aiSvc       *ai.Service
    broadcaster *StatusBroadcaster
}

// AIPayload is the job payload for AI processing
type AIPayload struct {
    DocumentID uuid.UUID `json:"document_id"`
}

// NewAIProcessor creates a new AI processor
func NewAIProcessor(aiSvc *ai.Service, broadcaster *StatusBroadcaster) *AIProcessor {
    return &AIProcessor{
        aiSvc:       aiSvc,
        broadcaster: broadcaster,
    }
}

// HandleJob processes an AI analysis job (implements queue.JobHandler)
func (p *AIProcessor) HandleJob(ctx context.Context, job *sqlc.Job) error {
    // Parse job payload
    var payload AIPayload
    if err := json.Unmarshal(job.Payload, &payload); err != nil {
        return fmt.Errorf("unmarshal ai payload: %w", err)
    }

    docID := payload.DocumentID
    jobID := job.ID
    start := time.Now()

    slog.Info("starting ai analysis",
        "doc_id", docID,
        "job_id", jobID,
        "attempt", job.Attempt)

    // Broadcast analysis starting
    p.broadcast(StatusUpdate{
        DocumentID: docID,
        Status:     "ai_processing",
    })

    // Run analysis
    suggestions, err := p.aiSvc.AnalyzeDocument(ctx, docID, &jobID)
    if err != nil {
        slog.Error("ai analysis failed",
            "doc_id", docID,
            "job_id", jobID,
            "error", err,
            "duration_ms", time.Since(start).Milliseconds())

        // Broadcast failure
        p.broadcast(StatusUpdate{
            DocumentID: docID,
            Status:     "ai_failed",
            Error:      err.Error(),
        })

        return err
    }

    // Count auto-applied vs pending
    var autoApplied, pending int
    for _, s := range suggestions {
        if s.Status == sqlc.SuggestionStatusAutoApplied {
            autoApplied++
        } else if s.Status == sqlc.SuggestionStatusPending {
            pending++
        }
    }

    slog.Info("ai analysis complete",
        "doc_id", docID,
        "job_id", jobID,
        "suggestions", len(suggestions),
        "auto_applied", autoApplied,
        "pending", pending,
        "duration_ms", time.Since(start).Milliseconds())

    // Broadcast completion
    p.broadcast(StatusUpdate{
        DocumentID: docID,
        Status:     "ai_complete",
    })

    return nil
}

// broadcast sends a status update to all SSE subscribers
func (p *AIProcessor) broadcast(update StatusUpdate) {
    if p.broadcaster != nil {
        p.broadcaster.Broadcast(update)
    }
}
```
  </action>
  <verify>Check ./tmp/air-combined.log for compilation errors</verify>
  <done>AIProcessor compiles and implements queue.JobHandler</done>
</task>

<task type="auto">
  <name>Task 3: Wire AI service and processor in main.go</name>
  <files>cmd/server/main.go</files>
  <action>
Update main.go to:

1. Import the ai package: `"docko/internal/ai"`

2. Create AI service after database is ready:
```go
// Create AI service
aiSvc := ai.NewService(db)
```

3. Create AI processor after broadcaster:
```go
// Create AI processor
aiProcessor := processing.NewAIProcessor(aiSvc, broadcaster)
```

4. Register AI queue handler after processing handler:
```go
// Register AI queue handler
q.RegisterHandler("ai_analyze", aiProcessor.HandleJob)
```

5. Start AI queue (can share processing queue or use separate):
```go
// Start AI processing queue
go q.Start(ctx, "ai")
```

6. Update handler.New to include aiSvc (or add it via a separate method).

The handler will need access to aiSvc for settings management and manual re-analyze triggers. Either:
- Add aiSvc to Handler struct and New function
- Or create separate AI handler

Choose option A (add to Handler) for consistency with existing patterns.
  </action>
  <verify>Check ./tmp/air-combined.log for compilation errors and server startup</verify>
  <done>AI service and processor wired into application startup</done>
</task>

</tasks>

<verification>
1. Service compiles: No errors in ./tmp/air-combined.log
2. Provider fallback works: Service tries providers in order
3. Suggestion storage: CreateAISuggestion called with correct params
4. Auto-apply: High-confidence suggestions create tags/correspondents
5. Queue handler registered: "ai_analyze" job type has handler
6. Server starts: Application runs with AI service initialized
</verification>

<success_criteria>
- AI service orchestrates provider selection with fallback
- AnalyzeDocument stores suggestions with proper status
- High-confidence suggestions auto-apply (create and assign tags/correspondents)
- Job handler processes AI analysis queue
- AI queue starts on server startup
- All code compiles and server runs
</success_criteria>

<output>
After completion, create `.planning/phases/08-ai-integration/08-03-SUMMARY.md`
</output>
