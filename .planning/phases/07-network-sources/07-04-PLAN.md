---
phase: 07-network-sources
plan: 04
type: execute
wave: 3
depends_on: ["07-02", "07-03"]
files_modified:
  - internal/network/service.go
  - internal/network/poller.go
autonomous: true

must_haves:
  truths:
    - "System polls enabled sources at fixed interval"
    - "System imports discovered PDFs through document service"
    - "System handles post-import actions (leave/delete/move)"
    - "System auto-disables sources after consecutive failures"
  artifacts:
    - path: "internal/network/service.go"
      provides: "Network service coordinating all sources"
      exports: ["Service", "New", "Start", "Stop", "SyncSource"]
    - path: "internal/network/poller.go"
      provides: "Background polling for continuous sync"
      exports: ["Poller"]
  key_links:
    - from: "internal/network/service.go"
      to: "internal/document/document.go"
      via: "Ingest method for importing files"
      pattern: "docSvc\\.Ingest"
    - from: "internal/network/poller.go"
      to: "internal/network/service.go"
      via: "SyncSource method"
      pattern: "service\\.SyncSource"
---

<objective>
Create network service that coordinates sync operations and polling.

Purpose: The service manages the sync lifecycle - connecting to sources, listing files, downloading PDFs, and handling post-import actions. The poller runs sync on a fixed interval for continuous sync sources.
Output: NetworkService with sync logic and background Poller.
</objective>

<execution_context>
@/home/bjk/.claude/get-shit-done/workflows/execute-plan.md
@/home/bjk/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07-network-sources/07-RESEARCH.md
@.planning/phases/07-network-sources/07-02-SUMMARY.md
@.planning/phases/07-network-sources/07-03-SUMMARY.md
@internal/inbox/service.go
@internal/document/document.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create network service</name>
  <files>internal/network/service.go</files>
  <action>
Create the network service that coordinates sync operations:

```go
package network

import (
    "context"
    "fmt"
    "io"
    "log/slog"
    "os"
    "path/filepath"
    "sync"
    "time"

    "github.com/google/uuid"
    "github.com/jackc/pgx/v5/pgtype"

    "docko/internal/config"
    "docko/internal/database"
    "docko/internal/database/sqlc"
    "docko/internal/document"
)

const (
    // MaxConsecutiveFailures before auto-disabling a source
    MaxConsecutiveFailures = 5
    // DefaultBatchSize for sync operations
    DefaultBatchSize = 100
    // TempFilePrefix for downloaded files
    TempFilePrefix = "network-sync-"
)

// Event action constants
const (
    ActionImported  = "imported"
    ActionDuplicate = "duplicate"
    ActionError     = "error"
    ActionSkipped   = "skipped"
)

// Service coordinates network source sync operations.
type Service struct {
    db     *database.DB
    docSvc *document.Service
    cfg    *config.Config
    crypto *CredentialCrypto
    poller *Poller
    mu     sync.RWMutex
    ctx    context.Context
    cancel context.CancelFunc
    wg     sync.WaitGroup
}

// New creates a new network Service.
func New(db *database.DB, docSvc *document.Service, cfg *config.Config) *Service {
    return &Service{
        db:     db,
        docSvc: docSvc,
        cfg:    cfg,
        crypto: NewCredentialCrypto(cfg.Auth.SessionSecret),
    }
}

// Start initializes and starts the background poller.
func (s *Service) Start(ctx context.Context) error {
    s.ctx, s.cancel = context.WithCancel(ctx)

    // Create and start poller
    s.poller = NewPoller(s, 5*time.Minute)
    s.wg.Add(1)
    go func() {
        defer s.wg.Done()
        if err := s.poller.Run(s.ctx); err != nil && err != context.Canceled {
            slog.Error("poller error", "error", err)
        }
    }()

    slog.Info("network service started")
    return nil
}

// Stop gracefully shuts down the network service.
func (s *Service) Stop() error {
    if s.cancel != nil {
        s.cancel()
    }
    s.wg.Wait()
    slog.Info("network service stopped")
    return nil
}

// TestConnection tests connectivity to a network source.
func (s *Service) TestConnection(ctx context.Context, cfg *sqlc.NetworkSource) error {
    source, err := NewSourceFromConfig(cfg, s.crypto)
    if err != nil {
        return fmt.Errorf("create source: %w", err)
    }
    defer source.Close()

    return source.Test(ctx)
}

// SyncSource synchronizes a single network source.
// Returns number of files imported and any error.
func (s *Service) SyncSource(ctx context.Context, sourceID uuid.UUID) (int, error) {
    // Load source config
    cfg, err := s.db.Queries.GetNetworkSource(ctx, sourceID)
    if err != nil {
        return 0, fmt.Errorf("get source: %w", err)
    }

    if !cfg.Enabled {
        return 0, fmt.Errorf("source is disabled")
    }

    // Create network source client
    source, err := NewSourceFromConfig(&cfg, s.crypto)
    if err != nil {
        s.recordSyncFailure(ctx, &cfg, err)
        return 0, fmt.Errorf("create source: %w", err)
    }
    defer source.Close()

    slog.Info("starting sync", "source", cfg.Name, "host", cfg.Host)

    // List PDF files
    files, err := source.ListPDFs(ctx)
    if err != nil {
        s.recordSyncFailure(ctx, &cfg, err)
        return 0, fmt.Errorf("list files: %w", err)
    }

    slog.Info("found PDF files", "source", cfg.Name, "count", len(files))

    // Apply batch size limit
    if len(files) > int(cfg.BatchSize) {
        files = files[:cfg.BatchSize]
        slog.Info("applying batch limit", "source", cfg.Name, "batch_size", cfg.BatchSize)
    }

    // Process each file
    imported := 0
    for _, file := range files {
        select {
        case <-ctx.Done():
            return imported, ctx.Err()
        default:
        }

        if err := s.importFile(ctx, source, &cfg, file); err != nil {
            slog.Warn("failed to import file", "file", file.Path, "error", err)
            s.logEvent(ctx, cfg.ID, file.Name, file.Path, ActionError, nil, err.Error())
            continue
        }
        imported++
    }

    // Reset failure count on successful sync
    if err := s.db.Queries.ResetConsecutiveFailures(ctx, cfg.ID); err != nil {
        slog.Warn("failed to reset failure count", "error", err)
    }

    // Update last sync time
    s.updateSyncStatus(ctx, cfg.ID, nil)

    slog.Info("sync complete", "source", cfg.Name, "imported", imported, "total", len(files))
    return imported, nil
}

// SyncAll synchronizes all enabled sources.
func (s *Service) SyncAll(ctx context.Context) error {
    sources, err := s.db.Queries.ListEnabledNetworkSources(ctx)
    if err != nil {
        return fmt.Errorf("list sources: %w", err)
    }

    for _, source := range sources {
        select {
        case <-ctx.Done():
            return ctx.Err()
        default:
        }

        if _, err := s.SyncSource(ctx, source.ID); err != nil {
            slog.Warn("sync failed", "source", source.Name, "error", err)
            // Continue with other sources
        }
    }
    return nil
}

// importFile downloads and ingests a single file.
func (s *Service) importFile(ctx context.Context, source NetworkSource, cfg *sqlc.NetworkSource, file RemoteFile) error {
    // Create temp file for download
    tmpFile, err := os.CreateTemp("", TempFilePrefix+"*.pdf")
    if err != nil {
        return fmt.Errorf("create temp file: %w", err)
    }
    tmpPath := tmpFile.Name()
    defer os.Remove(tmpPath)

    // Download file
    if err := source.ReadFile(ctx, file.Path, tmpFile); err != nil {
        tmpFile.Close()
        return fmt.Errorf("download: %w", err)
    }
    tmpFile.Close()

    // Ingest through document service
    doc, isDupe, err := s.docSvc.Ingest(ctx, tmpPath, file.Name)
    if err != nil {
        return fmt.Errorf("ingest: %w", err)
    }

    // Handle result
    if isDupe {
        s.logEvent(ctx, cfg.ID, file.Name, file.Path, ActionDuplicate, &doc.ID, "")
        slog.Debug("duplicate file", "file", file.Name, "existing_doc", doc.ID)
    } else {
        s.logEvent(ctx, cfg.ID, file.Name, file.Path, ActionImported, &doc.ID, "")
        if err := s.db.Queries.IncrementFilesImported(ctx, cfg.ID); err != nil {
            slog.Warn("failed to increment import count", "error", err)
        }
        slog.Info("imported file", "file", file.Name, "doc_id", doc.ID)
    }

    // Handle post-import action
    if err := s.handlePostImportAction(ctx, source, cfg, file); err != nil {
        slog.Warn("post-import action failed", "file", file.Path, "error", err)
        // Don't fail the import for post-action errors
    }

    return nil
}

// handlePostImportAction processes file after successful import.
func (s *Service) handlePostImportAction(ctx context.Context, source NetworkSource, cfg *sqlc.NetworkSource, file RemoteFile) error {
    switch cfg.PostImportAction {
    case sqlc.PostImportActionLeave:
        // Do nothing
        return nil

    case sqlc.PostImportActionDelete:
        return source.DeleteFile(ctx, file.Path)

    case sqlc.PostImportActionMove:
        // Move to subfolder
        subfolder := "imported"
        if cfg.MoveSubfolder != nil && *cfg.MoveSubfolder != "" {
            subfolder = *cfg.MoveSubfolder
        }

        // Construct destination path
        dir := filepath.Dir(file.Path)
        destPath := filepath.Join(dir, subfolder, file.Name)
        return source.MoveFile(ctx, file.Path, destPath)

    default:
        return nil
    }
}

// recordSyncFailure increments failure count and potentially disables source.
func (s *Service) recordSyncFailure(ctx context.Context, cfg *sqlc.NetworkSource, syncErr error) {
    errMsg := syncErr.Error()
    s.updateSyncStatus(ctx, cfg.ID, &errMsg)

    // Increment failure count
    newCount, err := s.db.Queries.IncrementConsecutiveFailures(ctx, cfg.ID)
    if err != nil {
        slog.Warn("failed to increment failure count", "error", err)
        return
    }

    // Auto-disable after too many failures
    if newCount >= MaxConsecutiveFailures {
        if err := s.db.Queries.DisableNetworkSource(ctx, cfg.ID); err != nil {
            slog.Warn("failed to disable source", "error", err)
            return
        }
        slog.Warn("source auto-disabled after consecutive failures",
            "source", cfg.Name,
            "failures", newCount,
        )
    }
}

// updateSyncStatus updates the source's sync timestamp and error.
func (s *Service) updateSyncStatus(ctx context.Context, sourceID uuid.UUID, errMsg *string) {
    state := "connected"
    if errMsg != nil {
        state = "error"
    }

    // Get current failure count
    source, _ := s.db.Queries.GetNetworkSource(ctx, sourceID)

    err := s.db.Queries.UpdateNetworkSourceStatus(ctx, sqlc.UpdateNetworkSourceStatusParams{
        ID:                  sourceID,
        ConnectionState:     &state,
        ConsecutiveFailures: source.ConsecutiveFailures,
        LastSyncAt:          pgtype.Timestamptz{Time: time.Now(), Valid: true},
        LastError:           errMsg,
    })
    if err != nil {
        slog.Warn("failed to update sync status", "error", err)
    }
}

// logEvent creates a network source event record.
func (s *Service) logEvent(ctx context.Context, sourceID uuid.UUID, filename, remotePath, action string, docID *uuid.UUID, errMsg string) {
    var pgDocID pgtype.UUID
    if docID != nil {
        pgDocID = pgtype.UUID{Bytes: *docID, Valid: true}
    }

    var errPtr *string
    if errMsg != "" {
        errPtr = &errMsg
    }

    _, err := s.db.Queries.CreateNetworkSourceEvent(ctx, sqlc.CreateNetworkSourceEventParams{
        SourceID:     sourceID,
        Filename:     filename,
        RemotePath:   remotePath,
        Action:       action,
        DocumentID:   pgDocID,
        ErrorMessage: errPtr,
    })
    if err != nil {
        slog.Warn("failed to log event", "error", err)
    }
}

// GetCrypto returns the credential crypto instance for use by handlers.
func (s *Service) GetCrypto() *CredentialCrypto {
    return s.crypto
}
```

Key design decisions:
- 5 consecutive failures before auto-disable (from research)
- Batch size limit prevents memory issues
- Temp file approach for downloads (same pattern as inbox)
- Post-import actions: leave, delete, or move to subfolder
- Event logging mirrors inbox pattern
  </action>
  <verify>Check ./tmp/air-combined.log for compilation errors</verify>
  <done>Network service compiles with sync logic and failure handling</done>
</task>

<task type="auto">
  <name>Task 2: Create background poller</name>
  <files>internal/network/poller.go</files>
  <action>
Create the poller that runs sync on a fixed interval:

```go
package network

import (
    "context"
    "log/slog"
    "time"
)

// Poller runs periodic sync for continuous-sync sources.
type Poller struct {
    service  *Service
    interval time.Duration
}

// NewPoller creates a new poller.
func NewPoller(service *Service, interval time.Duration) *Poller {
    return &Poller{
        service:  service,
        interval: interval,
    }
}

// Run starts the polling loop. Blocks until context is cancelled.
func (p *Poller) Run(ctx context.Context) error {
    // Run initial sync
    p.syncContinuousSources(ctx)

    ticker := time.NewTicker(p.interval)
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            p.syncContinuousSources(ctx)
        case <-ctx.Done():
            return ctx.Err()
        }
    }
}

// syncContinuousSources syncs all sources with continuous_sync enabled.
func (p *Poller) syncContinuousSources(ctx context.Context) {
    sources, err := p.service.db.Queries.ListContinuousSyncSources(ctx)
    if err != nil {
        slog.Error("failed to list continuous sync sources", "error", err)
        return
    }

    if len(sources) == 0 {
        return
    }

    slog.Debug("running scheduled sync", "sources", len(sources))

    for _, source := range sources {
        select {
        case <-ctx.Done():
            return
        default:
        }

        if _, err := p.service.SyncSource(ctx, source.ID); err != nil {
            slog.Warn("scheduled sync failed",
                "source", source.Name,
                "error", err,
            )
            // Continue with other sources
        }
    }
}

// TriggerSync manually triggers a sync for all continuous sources.
// Can be called from handler for "Sync All" button.
func (p *Poller) TriggerSync(ctx context.Context) {
    p.syncContinuousSources(ctx)
}
```

Design notes:
- 5-minute interval (from research recommendations)
- Only syncs sources with continuous_sync=true
- Runs initial sync on startup
- Graceful cancellation via context
- TriggerSync for manual "Sync All" button
  </action>
  <verify>Check ./tmp/air-combined.log for compilation errors</verify>
  <done>Poller runs background sync at 5-minute intervals</done>
</task>

</tasks>

<verification>
1. Code compiles: `go build ./...` succeeds
2. Service has Start/Stop lifecycle methods
3. SyncSource imports files through document service
4. Poller schedules sync at configured interval
5. Check ./tmp/air-combined.log for any compilation errors
</verification>

<success_criteria>
- Network Service coordinates sync operations
- SyncSource downloads, ingests, and handles post-import actions
- Failure count auto-disables after 5 consecutive errors
- Poller runs 5-minute sync cycle for continuous sync sources
- All code compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/07-network-sources/07-04-SUMMARY.md`
</output>
