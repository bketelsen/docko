---
phase: 01-foundation
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - internal/queue/queue.go
autonomous: true

must_haves:
  truths:
    - "Queue can enqueue jobs with payload"
    - "Queue can dequeue jobs atomically using SKIP LOCKED"
    - "Queue retries failed jobs with exponential backoff and jitter"
    - "Queue worker processes jobs and calls registered handlers"
    - "Jobs that exceed max attempts are marked as failed"
  artifacts:
    - path: "internal/queue/queue.go"
      provides: "Job queue implementation"
      exports: ["Queue", "New", "Enqueue", "Start", "Stop", "RegisterHandler"]
      min_lines: 150
  key_links:
    - from: "internal/queue/queue.go"
      to: "internal/database/sqlc/jobs.sql.go"
      via: "sqlc queries"
      pattern: "Queries\\.(EnqueueJob|DequeueJobs|CompleteJob|FailJob)"
---

<objective>
Implement the PostgreSQL-backed job queue with retry logic and worker processing.

Purpose: The queue system enables asynchronous document processing. Jobs are stored in PostgreSQL and claimed atomically using SKIP LOCKED pattern. Failed jobs are retried with exponential backoff and jitter to prevent thundering herd.

Output: internal/queue/queue.go with Queue struct, worker loop, and handler registration.
</objective>

<execution_context>
@/home/bjk/.claude/get-shit-done/workflows/execute-plan.md
@/home/bjk/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/01-foundation/01-CONTEXT.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
@internal/database/database.go
@internal/database/sqlc/jobs.sql.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement job queue with worker loop</name>
  <files>internal/queue/queue.go</files>
  <action>
Create internal/queue/queue.go implementing:

```go
package queue

import (
    "context"
    "encoding/json"
    "fmt"
    "log/slog"
    "math"
    "math/rand"
    "sync"
    "time"

    "github.com/google/uuid"

    "docko/internal/database"
    "docko/internal/database/sqlc"
)

// JobHandler processes a job and returns an error if it fails
type JobHandler func(ctx context.Context, job *sqlc.Job) error

// Config holds queue configuration
type Config struct {
    PollInterval    time.Duration // How often to check for jobs (default: 1s)
    VisibilityTimeout time.Duration // How long a job stays invisible (default: 5min)
    WorkerCount     int           // Number of concurrent workers (default: runtime.NumCPU())
    BaseRetryDelay  time.Duration // Base delay for exponential backoff (default: 1s)
    MaxRetryDelay   time.Duration // Maximum retry delay (default: 1h)
}

// DefaultConfig returns sensible defaults
func DefaultConfig() Config {
    return Config{
        PollInterval:      time.Second,
        VisibilityTimeout: 5 * time.Minute,
        WorkerCount:       4,
        BaseRetryDelay:    time.Second,
        MaxRetryDelay:     time.Hour,
    }
}

// Queue manages job processing
type Queue struct {
    db       *database.DB
    config   Config
    handlers map[string]JobHandler
    mu       sync.RWMutex
    wg       sync.WaitGroup
    stop     chan struct{}
    running  bool
}

// New creates a new Queue instance
func New(db *database.DB, config Config) *Queue {
    if config.PollInterval == 0 {
        config.PollInterval = time.Second
    }
    if config.WorkerCount == 0 {
        config.WorkerCount = 4
    }
    if config.BaseRetryDelay == 0 {
        config.BaseRetryDelay = time.Second
    }
    if config.MaxRetryDelay == 0 {
        config.MaxRetryDelay = time.Hour
    }

    return &Queue{
        db:       db,
        config:   config,
        handlers: make(map[string]JobHandler),
        stop:     make(chan struct{}),
    }
}

// RegisterHandler registers a handler for a job type
func (q *Queue) RegisterHandler(jobType string, handler JobHandler) {
    q.mu.Lock()
    defer q.mu.Unlock()
    q.handlers[jobType] = handler
}

// Enqueue adds a job to the queue
func (q *Queue) Enqueue(ctx context.Context, queueName, jobType string, payload any) (*sqlc.Job, error) {
    payloadJSON, err := json.Marshal(payload)
    if err != nil {
        return nil, fmt.Errorf("marshal payload: %w", err)
    }

    job, err := q.db.Queries.EnqueueJob(ctx, sqlc.EnqueueJobParams{
        QueueName: queueName,
        JobType:   jobType,
        Payload:   payloadJSON,
    })
    if err != nil {
        return nil, fmt.Errorf("enqueue job: %w", err)
    }

    slog.Info("job enqueued", "job_id", job.ID, "type", jobType, "queue", queueName)
    return &job, nil
}

// EnqueueTx adds a job within an existing transaction
func (q *Queue) EnqueueTx(ctx context.Context, qtx *sqlc.Queries, queueName, jobType string, payload any) (*sqlc.Job, error) {
    payloadJSON, err := json.Marshal(payload)
    if err != nil {
        return nil, fmt.Errorf("marshal payload: %w", err)
    }

    job, err := qtx.EnqueueJob(ctx, sqlc.EnqueueJobParams{
        QueueName: queueName,
        JobType:   jobType,
        Payload:   payloadJSON,
    })
    if err != nil {
        return nil, fmt.Errorf("enqueue job: %w", err)
    }

    return &job, nil
}

// Start begins processing jobs
func (q *Queue) Start(ctx context.Context, queueName string) {
    q.mu.Lock()
    if q.running {
        q.mu.Unlock()
        return
    }
    q.running = true
    q.mu.Unlock()

    slog.Info("queue starting", "queue", queueName, "workers", q.config.WorkerCount)

    for i := 0; i < q.config.WorkerCount; i++ {
        q.wg.Add(1)
        go q.worker(ctx, queueName, i)
    }
}

// Stop gracefully stops all workers
func (q *Queue) Stop() {
    q.mu.Lock()
    if !q.running {
        q.mu.Unlock()
        return
    }
    q.running = false
    q.mu.Unlock()

    close(q.stop)
    q.wg.Wait()
    slog.Info("queue stopped")
}

func (q *Queue) worker(ctx context.Context, queueName string, workerID int) {
    defer q.wg.Done()

    slog.Debug("worker started", "worker_id", workerID, "queue", queueName)

    ticker := time.NewTicker(q.config.PollInterval)
    defer ticker.Stop()

    for {
        select {
        case <-q.stop:
            slog.Debug("worker stopping", "worker_id", workerID)
            return
        case <-ctx.Done():
            slog.Debug("worker context cancelled", "worker_id", workerID)
            return
        case <-ticker.C:
            q.processJobs(ctx, queueName, workerID)
        }
    }
}

func (q *Queue) processJobs(ctx context.Context, queueName string, workerID int) {
    // Dequeue one job at a time per worker
    jobs, err := q.db.Queries.DequeueJobs(ctx, sqlc.DequeueJobsParams{
        QueueName: queueName,
        Limit:     1,
    })
    if err != nil {
        slog.Error("failed to dequeue jobs", "error", err, "worker_id", workerID)
        return
    }

    for _, job := range jobs {
        q.processJob(ctx, &job, workerID)
    }
}

func (q *Queue) processJob(ctx context.Context, job *sqlc.Job, workerID int) {
    q.mu.RLock()
    handler, ok := q.handlers[job.JobType]
    q.mu.RUnlock()

    if !ok {
        slog.Error("no handler for job type", "job_type", job.JobType, "job_id", job.ID)
        q.failJob(ctx, job.ID, fmt.Sprintf("no handler registered for job type: %s", job.JobType))
        return
    }

    slog.Info("processing job", "job_id", job.ID, "type", job.JobType, "attempt", job.Attempt, "worker_id", workerID)

    start := time.Now()
    err := handler(ctx, job)
    duration := time.Since(start)

    if err != nil {
        slog.Error("job failed", "job_id", job.ID, "error", err, "duration", duration, "attempt", job.Attempt)
        q.handleJobFailure(ctx, job, err)
        return
    }

    slog.Info("job completed", "job_id", job.ID, "duration", duration)
    if _, err := q.db.Queries.CompleteJob(ctx, job.ID); err != nil {
        slog.Error("failed to mark job complete", "job_id", job.ID, "error", err)
    }
}

func (q *Queue) handleJobFailure(ctx context.Context, job *sqlc.Job, jobErr error) {
    // Check if we've exhausted retries
    if job.Attempt >= job.MaxAttempts {
        slog.Warn("job exhausted retries", "job_id", job.ID, "attempts", job.Attempt)
        q.failJob(ctx, job.ID, jobErr.Error())
        return
    }

    // Schedule retry with exponential backoff + jitter
    delay := q.nextRetryDelay(job.Attempt)
    scheduledAt := time.Now().Add(delay)

    _, err := q.db.Queries.RetryJob(ctx, sqlc.RetryJobParams{
        ID:          job.ID,
        ScheduledAt: scheduledAt,
    })
    if err != nil {
        slog.Error("failed to schedule retry", "job_id", job.ID, "error", err)
        return
    }

    slog.Info("job scheduled for retry", "job_id", job.ID, "delay", delay, "scheduled_at", scheduledAt)
}

func (q *Queue) failJob(ctx context.Context, jobID uuid.UUID, errMsg string) {
    _, err := q.db.Queries.FailJob(ctx, sqlc.FailJobParams{
        ID:        jobID,
        LastError: &errMsg,
    })
    if err != nil {
        slog.Error("failed to mark job as failed", "job_id", jobID, "error", err)
    }
}

// nextRetryDelay calculates exponential backoff with full jitter
// Formula: random(0, min(cap, base * 2^attempt))
func (q *Queue) nextRetryDelay(attempt int32) time.Duration {
    backoff := float64(q.config.BaseRetryDelay) * math.Pow(2, float64(attempt))
    if backoff > float64(q.config.MaxRetryDelay) {
        backoff = float64(q.config.MaxRetryDelay)
    }
    jittered := rand.Float64() * backoff
    return time.Duration(jittered)
}
```

Key implementation details:
- Uses SKIP LOCKED via DequeueJobs query from plan 01
- Exponential backoff with full jitter per AWS Builders' Library
- Visibility timeout reclaims stuck jobs (included in DequeueJobs WHERE clause)
- Clean shutdown via Stop() waits for all workers
- EnqueueTx allows transactional job creation
- Uses slog for all logging
  </action>
  <verify>
Run `make dev` and check ./tmp/air-combined.log for compilation errors. The queue package should compile without errors.
  </verify>
  <done>internal/queue/queue.go exists and compiles. Queue can be instantiated, handlers registered, jobs enqueued, and workers started/stopped.</done>
</task>

<task type="auto">
  <name>Task 2: Add unit test for retry delay calculation</name>
  <files>internal/queue/queue_test.go</files>
  <action>
Create internal/queue/queue_test.go with a test for the backoff calculation:

```go
package queue

import (
    "testing"
    "time"
)

func TestNextRetryDelay(t *testing.T) {
    q := &Queue{
        config: Config{
            BaseRetryDelay: time.Second,
            MaxRetryDelay:  time.Hour,
        },
    }

    // Run multiple times to verify randomness stays within bounds
    for i := 0; i < 100; i++ {
        // Test attempt 0: should be between 0 and 1s
        delay0 := q.nextRetryDelay(0)
        if delay0 < 0 || delay0 > time.Second {
            t.Errorf("attempt 0: delay %v not in [0, 1s]", delay0)
        }

        // Test attempt 2: should be between 0 and 4s
        delay2 := q.nextRetryDelay(2)
        if delay2 < 0 || delay2 > 4*time.Second {
            t.Errorf("attempt 2: delay %v not in [0, 4s]", delay2)
        }

        // Test attempt 10: should cap at MaxRetryDelay
        delay10 := q.nextRetryDelay(10)
        if delay10 < 0 || delay10 > time.Hour {
            t.Errorf("attempt 10: delay %v not in [0, 1h]", delay10)
        }
    }
}

func TestDefaultConfig(t *testing.T) {
    cfg := DefaultConfig()

    if cfg.PollInterval != time.Second {
        t.Errorf("expected PollInterval 1s, got %v", cfg.PollInterval)
    }
    if cfg.WorkerCount != 4 {
        t.Errorf("expected WorkerCount 4, got %d", cfg.WorkerCount)
    }
    if cfg.BaseRetryDelay != time.Second {
        t.Errorf("expected BaseRetryDelay 1s, got %v", cfg.BaseRetryDelay)
    }
    if cfg.MaxRetryDelay != time.Hour {
        t.Errorf("expected MaxRetryDelay 1h, got %v", cfg.MaxRetryDelay)
    }
}
```

This tests:
- Backoff stays within expected bounds for each attempt
- Jitter produces values between 0 and max (not always max)
- MaxRetryDelay caps the backoff
- DefaultConfig returns expected values
  </action>
  <verify>
Run `go test ./internal/queue/... -v` and verify all tests pass.
  </verify>
  <done>Queue tests pass. Backoff calculation verified to stay within bounds with jitter.</done>
</task>

</tasks>

<verification>
1. Queue package compiles: `make dev` shows no errors in ./tmp/air-combined.log
2. Tests pass: `go test ./internal/queue/... -v` shows all tests passing
3. Handler registration works: Queue.RegisterHandler stores handlers in map
4. Enqueue works: Queue.Enqueue calls sqlc EnqueueJob query
5. Worker loop exists: Start() spawns workers that poll and process
</verification>

<success_criteria>
- internal/queue/queue.go implements Queue with Start, Stop, Enqueue, EnqueueTx, RegisterHandler
- Uses SKIP LOCKED pattern via sqlc queries from plan 01
- Exponential backoff with full jitter (AWS Builders' Library formula)
- Failed jobs are marked failed after max_attempts exhausted
- Tests verify backoff calculation bounds
- All code uses slog for logging (no fmt.Printf)
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-02-SUMMARY.md`
</output>
