---
phase: 14-production-readiness
plan: 03
type: execute
wave: 2
depends_on:
  - 14-01
  - 14-02
files_modified:
  - README.md
autonomous: false

must_haves:
  truths:
    - "README.md provides complete setup instructions"
    - "README.md documents all configuration options"
    - "README.md includes production deployment steps"
    - "README.md includes backup and restore procedures"
    - "README.md includes troubleshooting section"
  artifacts:
    - path: "README.md"
      provides: "Complete project documentation"
      min_lines: 300
  key_links:
    - from: "README.md"
      to: ".envrc.example"
      via: "environment variable reference"
      pattern: "Configuration"
    - from: "README.md"
      to: "docker-compose.prod.yml"
      via: "deployment instructions"
      pattern: "docker-compose.prod.yml"
---

<objective>
Create comprehensive README.md with setup, configuration, deployment, backup, upgrade, and troubleshooting documentation.

Purpose: Enable users to deploy, maintain, and troubleshoot Docko independently without additional support.
Output: Complete README.md covering all aspects of the project.
</objective>

<execution_context>
@/home/bjk/.claude/get-shit-done/workflows/execute-plan.md
@/home/bjk/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/14-production-readiness/14-CONTEXT.md
@.planning/phases/14-production-readiness/14-RESEARCH.md
@.planning/phases/14-production-readiness/14-01-SUMMARY.md
@.planning/phases/14-production-readiness/14-02-SUMMARY.md
@.envrc.example
@docker-compose.prod.yml
@Dockerfile
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create comprehensive README.md</name>
  <files>README.md</files>
  <action>
Create README.md with the following structure. Reference .envrc.example for complete environment variable list.

```markdown
# Docko

PDF document management system for households and small teams. Ingest documents from local directories and network shares (SMB/NFS), extract text with OCR fallback, auto-tag with AI, and search across tens of thousands of documents.

## Features

- **Web Upload**: Drag-and-drop PDF upload with bulk support
- **Inbox Watching**: Auto-import from local directories
- **Network Shares**: Import from SMB and NFS shares
- **Text Extraction**: Embedded text extraction with OCRmyPDF fallback
- **Full-Text Search**: PostgreSQL-powered search with tag and date filters
- **AI Tagging**: Auto-suggest tags and correspondents (OpenAI, Anthropic, Ollama)
- **Tag Management**: Create, edit, merge tags and correspondents
- **PDF Viewer**: In-browser preview and download

## Quick Start (Development)

### Prerequisites

- Go 1.24+
- Docker and Docker Compose
- Node.js (for Tailwind CSS)
- direnv (recommended)

### Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/docko.git
cd docko

# Start PostgreSQL and OCRmyPDF
docker compose up -d

# Copy environment example and configure
cp .envrc.example .envrc
# Edit .envrc with your settings
direnv allow

# Install Go dependencies
go mod download

# Install dev tools (templ, sqlc, air, tailwind)
make setup

# Start development server with hot reload
make dev
```

The app will be available at http://localhost:3000

## Production Deployment

### Prerequisites

- Docker and Docker Compose v2
- Domain name (optional, for SSL via reverse proxy)

### Configuration

Copy the environment example and configure all required variables:

```bash
cp .envrc.example .envrc.prod
```

#### Required Environment Variables

| Variable | Description |
|----------|-------------|
| `DATABASE_URL` | PostgreSQL connection string |
| `ADMIN_PASSWORD` | Admin user password (bcrypt hashed on startup) |
| `SESSION_SECRET` | HMAC secret for session cookies (generate with `openssl rand -hex 32`) |
| `CREDENTIAL_ENCRYPTION_KEY` | AES key for network share credentials (generate with `openssl rand -hex 32`) |

#### Optional Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `PORT` | 3000 | HTTP server port |
| `ENV` | development | Environment (development/production) |
| `LOG_LEVEL` | INFO | Logging level (DEBUG/INFO/WARN/ERROR) |
| `SITE_NAME` | Docko | Displayed in UI and meta tags |
| `SITE_URL` | - | Base URL for canonical links |
| `INBOX_PATH` | - | Default inbox directory path |
| `OPENAI_API_KEY` | - | OpenAI API key for AI tagging |
| `ANTHROPIC_API_KEY` | - | Anthropic API key for AI tagging |
| `OLLAMA_URL` | - | Ollama server URL (e.g., http://localhost:11434) |
| `OLLAMA_MODEL` | llama3.2 | Ollama model for AI tagging |

See `.envrc.example` for complete list with descriptions.

### Docker Compose Deployment

1. **Generate secrets:**

```bash
# Session secret
export SESSION_SECRET=$(openssl rand -hex 32)
echo "SESSION_SECRET=$SESSION_SECRET"

# Credential encryption key
export CREDENTIAL_ENCRYPTION_KEY=$(openssl rand -hex 32)
echo "CREDENTIAL_ENCRYPTION_KEY=$CREDENTIAL_ENCRYPTION_KEY"

# Strong admin password
export ADMIN_PASSWORD="your-secure-password-here"
```

2. **Set environment variables:**

Create a `.env` file or export variables:

```bash
export DATABASE_URL="postgres://docko:your-db-password@postgres:5432/docko?sslmode=disable"
export POSTGRES_PASSWORD="your-db-password"
export ADMIN_PASSWORD="your-admin-password"
export SESSION_SECRET="<generated-above>"
export CREDENTIAL_ENCRYPTION_KEY="<generated-above>"
export SITE_URL="https://docko.example.com"
```

3. **Create storage directories:**

```bash
mkdir -p storage/ocr-input storage/ocr-output
```

4. **Deploy:**

```bash
# Build and start all services
docker compose -f docker-compose.prod.yml up -d --build

# Check status
docker compose -f docker-compose.prod.yml ps

# View logs
docker compose -f docker-compose.prod.yml logs -f app
```

5. **Access the application:**

Navigate to http://your-server:3000 (or configure a reverse proxy for SSL).

### Reverse Proxy (SSL)

Docko runs on HTTP. Use a reverse proxy like nginx or Caddy for SSL termination:

**nginx example:**

```nginx
server {
    listen 443 ssl;
    server_name docko.example.com;

    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;

    location / {
        proxy_pass http://localhost:3000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

**Caddy example (auto-SSL):**

```caddyfile
docko.example.com {
    reverse_proxy localhost:3000
}
```

## Backup & Restore

### Database Backup

```bash
# Create backup
docker exec docko-postgres pg_dump -U docko docko > backup-$(date +%Y%m%d).sql

# Compressed backup
docker exec docko-postgres pg_dump -U docko docko | gzip > backup-$(date +%Y%m%d).sql.gz
```

### Database Restore

```bash
# From plain SQL
docker exec -i docko-postgres psql -U docko docko < backup.sql

# From compressed backup
gunzip -c backup.sql.gz | docker exec -i docko-postgres psql -U docko docko
```

### Document Storage Backup

```bash
# Backup storage volume
docker run --rm \
  -v docko-storage:/data \
  -v $(pwd):/backup \
  alpine tar czf /backup/storage-$(date +%Y%m%d).tar.gz -C /data .
```

### Document Storage Restore

```bash
# Restore storage volume
docker run --rm \
  -v docko-storage:/data \
  -v $(pwd):/backup \
  alpine sh -c "cd /data && tar xzf /backup/storage-backup.tar.gz"
```

### Full Backup Script

```bash
#!/bin/bash
DATE=$(date +%Y%m%d-%H%M%S)
BACKUP_DIR="./backups/$DATE"
mkdir -p "$BACKUP_DIR"

# Database
docker exec docko-postgres pg_dump -U docko docko | gzip > "$BACKUP_DIR/database.sql.gz"

# Storage
docker run --rm -v docko-storage:/data -v "$BACKUP_DIR":/backup alpine tar czf /backup/storage.tar.gz -C /data .

echo "Backup complete: $BACKUP_DIR"
```

## Upgrade Procedures

### Standard Upgrade

1. **Backup first:**

```bash
./backup.sh  # Or manual backup commands above
```

2. **Pull latest code:**

```bash
git pull origin main
```

3. **Rebuild and restart:**

```bash
docker compose -f docker-compose.prod.yml up -d --build
```

4. **Verify:**

```bash
docker compose -f docker-compose.prod.yml ps
docker compose -f docker-compose.prod.yml logs app | tail -20
```

### Database Migrations

Migrations run automatically on startup. If a migration fails:

1. Check logs: `docker compose -f docker-compose.prod.yml logs app`
2. Restore from backup if needed
3. Fix the issue and restart

### Breaking Changes

Check release notes before upgrading. If environment variables changed:

1. Compare `.envrc.example` with your configuration
2. Add any new required variables
3. Restart services

## Troubleshooting

### Container Won't Start

**Check logs:**
```bash
docker compose -f docker-compose.prod.yml logs app
```

**Common issues:**

- `connection refused` to postgres: Wait for postgres health check to pass
- `missing required environment variable`: Check all required vars are set
- `permission denied`: Ensure storage directories exist and are writable

### Health Check Failing

**Verify health endpoint:**
```bash
curl http://localhost:3000/health
# Should return: OK
```

**Check container health:**
```bash
docker inspect docko-app | grep -A 10 Health
```

### Database Connection Issues

**Test connection:**
```bash
docker exec docko-postgres psql -U docko -d docko -c "SELECT 1"
```

**Check DATABASE_URL format:**
```
postgres://user:password@host:port/database?sslmode=disable
```

### OCR Not Working

**Check OCRmyPDF service:**
```bash
docker compose -f docker-compose.prod.yml logs ocrmypdf
```

**Verify directories:**
```bash
ls -la storage/ocr-input storage/ocr-output
```

**Manual test:**
```bash
cp test.pdf storage/ocr-input/
# Wait 30 seconds
ls storage/ocr-output/
```

### AI Tagging Not Working

**Check provider configuration:**
- OpenAI: `OPENAI_API_KEY` must be set
- Anthropic: `ANTHROPIC_API_KEY` must be set
- Ollama: `OLLAMA_URL` must point to running Ollama server

**Check AI settings in UI:** Navigate to Settings > AI to verify provider is configured.

### High Memory Usage

**Check container stats:**
```bash
docker stats
```

**Adjust resource limits** in docker-compose.prod.yml if needed.

### Logs Filling Disk

Docker logging is configured with rotation. If logs are still growing:

```bash
# Check log sizes
docker system df -v

# Recreate containers to apply logging config
docker compose -f docker-compose.prod.yml down
docker compose -f docker-compose.prod.yml up -d
```

## Development

### Project Structure

```
cmd/server/          Entry point and slog config
internal/
  auth/              Authentication service
  config/            Environment configuration
  database/          Database connection, migrations, sqlc
  handler/           HTTP handlers
  middleware/        Echo middleware
  ...
templates/           Templ templates
components/          templUI components
static/              Static assets (CSS, JS, images)
sqlc/                SQL queries and configuration
```

### Key Commands

| Command | Description |
|---------|-------------|
| `make dev` | Start with hot reload |
| `make build` | Build production binary |
| `make test` | Run tests |
| `make lint` | Run linters |
| `make generate` | Regenerate templ + sqlc |
| `make migrate` | Run migrations |
| `make css-watch` | Watch Tailwind CSS |

### Tech Stack

- **Backend**: Go, Echo framework
- **Templates**: Templ
- **Frontend**: HTMX, Tailwind CSS, templUI components
- **Database**: PostgreSQL, sqlc
- **OCR**: OCRmyPDF (Docker service)

## License

[Add your license here]
```

Ensure all sections are complete and accurate based on:
- .envrc.example for environment variables
- docker-compose.prod.yml for deployment commands
- Actual project structure for dev section
  </action>
  <verify>
```bash
# Verify README exists and has substantial content
wc -l README.md  # Should be 300+ lines

# Check key sections exist
grep -c "## Quick Start" README.md
grep -c "## Production Deployment" README.md
grep -c "## Backup" README.md
grep -c "## Troubleshooting" README.md
```
  </verify>
  <done>
- README.md created with all required sections
- Setup, configuration, deployment documented
- Backup/restore procedures included
- Troubleshooting section complete
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete production readiness package:
- Security audit (Plan 01)
- .gitignore expansion (Plan 02)
- docker-compose.prod.yml (Plan 02)
- Comprehensive README.md (Plan 03)
  </what-built>
  <how-to-verify>
1. **Review README.md** - Open README.md and verify:
   - Quick Start section is accurate
   - All environment variables documented
   - Production deployment steps are clear
   - Backup/restore commands work
   - Troubleshooting covers common issues

2. **Test docker-compose.prod.yml** (optional):
   ```bash
   # Set required env vars
   export DATABASE_URL="postgres://docko:test@postgres:5432/docko?sslmode=disable"
   export POSTGRES_PASSWORD="test"
   export ADMIN_PASSWORD="test"
   export SESSION_SECRET=$(openssl rand -hex 32)
   export CREDENTIAL_ENCRYPTION_KEY=$(openssl rand -hex 32)

   # Validate compose
   docker compose -f docker-compose.prod.yml config

   # Optionally test deployment
   docker compose -f docker-compose.prod.yml up -d
   curl http://localhost:3000/health
   docker compose -f docker-compose.prod.yml down
   ```

3. **Verify .gitignore** - Check sensitive patterns are covered:
   ```bash
   cat .gitignore | grep -E "\.pem|\.key|credentials"
   ```

4. **Confirm security audit** - Plan 01 summary shows clean results
  </how-to-verify>
  <resume-signal>
Type "approved" if documentation is complete and accurate
Or describe any issues/corrections needed
  </resume-signal>
</task>

</tasks>

<verification>
- [ ] README.md exists with 300+ lines
- [ ] Quick Start section is accurate
- [ ] Production Deployment section is complete
- [ ] All environment variables documented
- [ ] Backup/restore procedures included
- [ ] Troubleshooting section covers common issues
- [ ] Human verification passed
</verification>

<success_criteria>
- README.md provides complete setup, configuration, and deployment instructions
- Documentation enables independent deployment and maintenance
- Human review confirms accuracy and completeness
</success_criteria>

<output>
After completion, create `.planning/phases/14-production-readiness/14-03-SUMMARY.md`

Include:
- README sections created
- Documentation completeness assessment
- Any issues found during review
- Phase 14 completion status
</output>
